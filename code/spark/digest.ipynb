{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import HiveContext\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from  scipy.stats import fisher_exact, ttest_ind\n",
    "\n",
    "content = [line.rstrip() for line in open('jobsArguments.conf')]\n",
    "\n",
    "analysisName=content[0]\n",
    "scope=content[1]\n",
    "scale=content[2]\n",
    "sqlControl=content[3]\n",
    "sqlCase=content[4]\n",
    "group1name=content[5]\n",
    "group2name=content[6]\n",
    "controlMAF=content[7]\n",
    "caseMAF=content[8]\n",
    "pathVariants=content[9]\n",
    "\n",
    "nPartitions=8\n",
    "conf = (SparkConf()\n",
    "         .setMaster(\"local[\"+str(nPartitions)+\"]\")\n",
    "         .setAppName(analysisName)\n",
    "       )\n",
    "sc.stop()\n",
    "from pyspark import BasicProfiler\n",
    "class MyCustomProfiler(BasicProfiler):\n",
    "     def show(self, id):\n",
    "         print(\"My custom profiles for RDD:%s\" % id)\n",
    "\n",
    "conf = SparkConf().set(\"spark.python.profile\", \"true\")\n",
    "#sc = SparkContext('local', 'test', conf=conf, profiler_cls=MyCustomProfiler)\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "\n",
    "#parquetFile = sqlContext.read.parquet(\"/user/hive/warehouse/gvr4.db/variantsulb\")\n",
    "#parquetFile = sqlContext.read.parquet(\"/Users/yalb/Projects/Github/Docker/cdh54_4_add1000g/variants2\")\n",
    "#parquetFile = sqlContext.read.parquet(\"hdfs://127.0.0.1:8020/user/hive/warehouse/gvr.db/test\")\n",
    "#parquetFile = sqlContext.read.parquet(\"hdfs://localhost/user/hive/warehouse/gvr3.db/variants\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sqlContext = SQLContext(sc)\n",
    "#sqlContext.sql(\"SET spark.sql.parquet.binaryAsString=true\")\n",
    "\n",
    "#pathVariants='/user/hive/warehouse/dbtest.db/data10000_100_10000p'\n",
    "\n",
    "#scale='gene'\n",
    "#scope='monogenic'\n",
    "#sqlCase=\"where sample_id<=50 and gene_symbol<=800\"\n",
    "#sqlControl=\"where sample_id>50 and sample_id<=100 and gene_symbol<=800\"\n",
    "#patientCase=range(1,51)\n",
    "#patientControl=range(51,101)\n",
    "#caseMAF=1.0\n",
    "#controlMAF=1.0\n",
    "#fields = [StructField(\"sample_id\", IntegerType(), False),StructField(\"chr\", StringType(), False),StructField(\"pos\", IntegerType(), False),StructField(\"ref\", StringType(), False),StructField(\"alt\", Str$\n",
    "#schema = StructType(fields)\n",
    "#csvfile = sqlContext.read.format('com.databricks.spark.csv',).schema(schema).load(pathVariants).repartition(2000)\n",
    "#csvfile.registerTempTable(\"variantData\");\n",
    "#parquetFile = sqlContext.read.parquet(pathVariants)\n",
    "#parquetFile.registerTempTable(\"variantData\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sqlContext = HiveContext(sc) #sqlContext._get_hive_ctx() #HiveContext(sc) \n",
    "p=5\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "sqlContext.sql(\"SET spark.sql.parquet.binaryAsString=true\")\n",
    "\n",
    "pathVariants='/Users/yalb/Projects/Github/digest/variantsulb1000gsubset'\n",
    "parquetFile = sqlContext.read.parquet(pathVariants)\n",
    "parquetFile.registerTempTable(\"variantData\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Input is vector patient, chr, pos, ref, alt, gene_symbol, zygosity\n",
    "def createKey_VariantGene(variantData):\n",
    "    #ID is chr:pos:ref:alt\n",
    "    ID=variantData[1]+\":\"+str(variantData[2])+\":\"+variantData[3]+\":\"+variantData[4]\n",
    "    \n",
    "    #return ID, gene_symbol, patient, zygosity\n",
    "    zygosity=1\n",
    "    #if variantData[6]==\"Homozygous\":\n",
    "    if variantData[6]==2:\n",
    "        zygosity=2\n",
    "    patientsID_dictionnary=patientsID_dictionnary_b.value\n",
    "    patientIndex=patientsID_dictionnary[variantData[0]]\n",
    "    return ((ID,variantData[5]),(patientIndex,zygosity))\n",
    "\n",
    "#variantGeneEntry: key is (variantID,gene), value is (patientIndex,zygosity)\n",
    "def geneAsKey(variantGeneEntry):    \n",
    "    return (variantGeneEntry[0][1],(variantGeneEntry[0][0],variantGeneEntry[1]))\n",
    "\n",
    "def createPairs(k,v,idList):\n",
    "    idListOthers=idList[:]\n",
    "    idListOthers.remove(k)\n",
    "    return [(str(sorted([k,idElt])),(sorted([k,idElt]),v)) for idElt in idListOthers]\n",
    "\n",
    "def getVariantID(key_VariantGene):\n",
    "    return key_VariantGene[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Transform sparse data (list of (sample_id,zygozity)) into vector z_i\n",
    "def vectorize(genotypeDataList):\n",
    "    genotypeVector=[0]*len(patientsID_dictionnary_b.value)\n",
    "    if len(genotypeDataList)>0:\n",
    "        for j in range(0,len(genotypeDataList)):\n",
    "            genotypeVector[genotypeDataList[j][0]]=genotypeDataList[j][1]\n",
    "        \n",
    "        sumCase=float(sum([int(x>0) for x in genotypeVector[0:patientsID_split_index_b.value]]))\n",
    "        sumControl=float(sum([int(x>0) for x in genotypeVector[patientsID_split_index_b.value:len(patientsID_dictionnary_b.value)]]))\n",
    "    \n",
    "        ratioCase=sumCase/patientsID_split_index_b.value\n",
    "        ratioControl=sumControl/(len(patientsID_dictionnary_b.value)-patientsID_split_index_b.value)\n",
    "        \n",
    "        if (ratioCase>float(caseMAF_b.value)) or (ratioControl>float(controlMAF_b.value)):\n",
    "            genotypeVector=[0]*len(patientsID_dictionnary_b.value)\n",
    "        \n",
    "    return genotypeVector        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Compute burden for variantList\n",
    "def burden(variantList):\n",
    "    variantList=list(variantList)\n",
    "    burden=[0]*len(patientsID_dictionnary_b.value)\n",
    "    \n",
    "    if len(variantList)>0:\n",
    "        #Go through list of variants\n",
    "        for i in range(0,len(variantList)):\n",
    "            #Get variant ID, and list of sample_index,genotype\n",
    "            (variantID,genotypeDataList)=variantList[i]\n",
    "            if genotypeDataList.__class__==tuple:\n",
    "                genotypeDataList=[genotypeDataList]\n",
    "            else:\n",
    "                genotypeDataList=list(genotypeDataList)\n",
    "            \n",
    "            #Get genotype vector for current variantID\n",
    "            genotypeDataVector=vectorize(genotypeDataList)\n",
    "            #And sum with previous genotype vectors\n",
    "            burden=[x+y for x,y in zip(burden,genotypeDataVector)]\n",
    "    \n",
    "    return burden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#variantList is [(locusID,[genotype])]\n",
    "def scoreVariant(key_VariantGene,value_GenotypeList):\n",
    "    genotypeList=list(value_GenotypeList)\n",
    "    \n",
    "    patientsID_dictionnary=patientsID_dictionnary_b.value\n",
    "    patientsID_split_index=patientsID_split_index_b.value\n",
    "    \n",
    "    genotypeVector=getGenotypeVector(genotypeList)\n",
    "    \n",
    "    #sumCase=float(sum([int(x>0) for x in genotypeVector[0:patientsID_split_index]]))\n",
    "    #sumControl=float(sum([int(x>0) for x in genotypeVector[patientsID_split_index:len(patientsID_dictionnary)]]))\n",
    "    sumCase=float(sum([x for x in genotypeVector[0:patientsID_split_index]]))\n",
    "    sumControl=float(sum([x for x in genotypeVector[patientsID_split_index:len(patientsID_dictionnary)]]))\n",
    "    \n",
    "    ratioCase=sumCase/patientsID_split_index\n",
    "    ratioControl=sumControl/(len(patientsID_dictionnary)-patientsID_split_index)\n",
    "        \n",
    "    score=ratioCase-ratioControl\n",
    "    #pvalue=fisher_exact([[sumCase,patientsID_split_index-sumCase],[sumControl,len(patientsID_dictionnary)-patientsID_split_index]],'greater')[1]\n",
    "    pvalue=ttest_ind(genotypeVector[0:patientsID_split_index],genotypeVector[patientsID_split_index:len(patientsID_dictionnary)])[1]/2\n",
    "    \n",
    "    \n",
    "    #if score>0:\n",
    "    return (key_VariantGene,(score,pvalue,ratioCase,ratioControl,sumCase,sumControl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scoreVariantPair(variantIDpair,value_GenotypeListPair):\n",
    "    \n",
    "    genotypeListPair=list(value_GenotypeListPair)\n",
    "    \n",
    "    patientsID_dictionnary=patientsID_dictionnary_b.value\n",
    "    patientsID_split_index=patientsID_split_index_b.value\n",
    "    \n",
    "    score=0\n",
    "    if len(genotypeListPair)==2:\n",
    "        (variantID,genotypeList1)=genotypeListPair[0]\n",
    "        (variantID,genotypeList2)=genotypeListPair[1]\n",
    "        \n",
    "        variantID1=variantID[0]\n",
    "        variantID2=variantID[1]\n",
    "        \n",
    "        genotypeList1=list(genotypeList1)\n",
    "        genotypeList2=list(genotypeList2)\n",
    "        \n",
    "        genotypeVector1=getGenotypeVector(genotypeList1)\n",
    "        genotypeVector2=getGenotypeVector(genotypeList2)\n",
    "        \n",
    "        genotypeVector=[int(x>0 and y>0) for x,y in zip(genotypeVector1,genotypeVector2)]\n",
    "        \n",
    "        sumCase=float(sum([int(x>0) for x in genotypeVector[0:patientsID_split_index]]))\n",
    "        ratioCase=sumCase/patientsID_split_index\n",
    "        sumControl=float(sum([int(x>0) for x in genotypeVector[(patientsID_split_index+1):len(patientsID_dictionnary)]]))\n",
    "        ratioControl=sumControl/(len(patientsID_dictionnary)-patientsID_split_index)\n",
    "        \n",
    "        score=ratioCase-ratioControl\n",
    "        pvalue=fisher_exact([[sumCase,patientsID_split_index-sumCase],[sumControl,len(patientsID_dictionnary)-patientsID_split_index]],'greater')[1]\n",
    "        \n",
    "        #if score>0:\n",
    "        return (variantIDpair,((variantID1,variantID2),score,pvalue,ratioCase,ratioControl,sumCase,sumControl))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#variantList is [(locusID,[sample_index,genotype])]\n",
    "def scoreGene(block):\n",
    "    block=list(block)\n",
    "    lenb=len(block)\n",
    "    scores=[]\n",
    "    \n",
    "    patientsID_dictionnary=patientsID_dictionnary_b.value\n",
    "    patientsID_split_index=patientsID_split_index_b.value\n",
    "    \n",
    "    if lenb>0:\n",
    "        for i in range(0,lenb):\n",
    "            listLoadBlock=block[i]\n",
    "    \n",
    "            sumCase=float(sum([int(x>0) for x in listLoadBlock[1][0:patientsID_split_index]]))\n",
    "            sumControl=float(sum([int(x>0) for x in listLoadBlock[1][patientsID_split_index:len(patientsID_dictionnary)]]))\n",
    "    \n",
    "            ratioCase=sumCase/patientsID_split_index\n",
    "            ratioControl=sumControl/(len(patientsID_dictionnary)-patientsID_split_index)\n",
    "        \n",
    "            score=ratioCase-ratioControl\n",
    "            pvalue=fisher_exact([[sumCase,patientsID_split_index-sumCase],[sumControl,len(patientsID_dictionnary)-patientsID_split_index]],'greater')[1]\n",
    "            #pvalue=ttest_ind(genotypeVectorByGene[0:patientsID_split_index],genotypeVectorByGene[patientsID_split_index:len(patientsID_dictionnary)])[1]/2\n",
    "        \n",
    "            if score>0:\n",
    "                scores.append((listLoadBlock[0],(score,pvalue,ratioCase,ratioControl,sumCase,sumControl)))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scoreGenePair(block1,block2):\n",
    "    block1=list(block1)\n",
    "    lenb1=len(block1)\n",
    "    lenb2=len(block2)\n",
    "    scores=[]\n",
    "\n",
    "    patientsID_dictionnary=patientsID_dictionnary_b.value\n",
    "    \n",
    "    patientsID_split_index=patientsID_split_index_b.value\n",
    "    \n",
    "    if lenb1>0 and lenb2>0:\n",
    "        for i in range(0,lenb1):\n",
    "            for j in range(0,lenb2):\n",
    "                listLoadBlock1=block1[i]\n",
    "                listLoadBlock2=block2[j]\n",
    "                if listLoadBlock1[0]>listLoadBlock2[0]:\n",
    "                    genoSum=[int(x>0 and y>0) for x,y in zip(listLoadBlock1[1],listLoadBlock2[1])]\n",
    "                    sumCase=float(sum([int(x>0) for x in genoSum[0:patientsID_split_index]]))\n",
    "                    sumControl=float(sum([int(x>0) for x in genoSum[(patientsID_split_index):len(patientsID_dictionnary)]]))\n",
    "        \n",
    "                    ratioCase=sumCase/patientsID_split_index\n",
    "                    ratioControl=sumControl/(len(patientsID_dictionnary)-patientsID_split_index)\n",
    "        \n",
    "                    score=ratioCase-ratioControl\n",
    "                    pvalue=fisher_exact([[sumCase,patientsID_split_index-sumCase],[sumControl,len(patientsID_dictionnary)-patientsID_split_index]],'greater')[1]\n",
    "        \n",
    "                    if score>0:\n",
    "                        scores.append(((listLoadBlock1[0],listLoadBlock2[0]),((listLoadBlock1[0],listLoadBlock2[0]),score,pvalue,ratioCase,ratioControl,sumCase,sumControl)))\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "variants_case = sqlContext.sql(\"SELECT sample_id,chr,pos,ref,alt,gene_symbol,zygosity FROM variantData \"+sqlCase)\n",
    "patientsID_case = sqlContext.sql(\"SELECT distinct sample_id FROM variantData \"+sqlCase).collect()\n",
    "#patientsID_case=sorted(variants_case.map(lambda v:v[0]).distinct().collect())\n",
    "patientsID_case = [patients[0] for patients in patientsID_case]\n",
    "\n",
    "variants_control= sqlContext.sql(\"SELECT sample_id,chr,pos,ref,alt,gene_symbol,zygosity FROM variantData \"+sqlControl)\n",
    "patientsID_control = sqlContext.sql(\"SELECT distinct sample_id FROM variantData \"+sqlControl).collect()\n",
    "#patientsID_control=sorted(variants_control.map(lambda v:v[0]).distinct().collect())\n",
    "patientsID_control = [patients[0] for patients in patientsID_control]\n",
    "\n",
    "patientsID=patientsID_case+patientsID_control\n",
    "patientsID_dictionnary=dict(zip(patientsID,range(len(patientsID))))\n",
    "\n",
    "patientsID_split_index_b = sc.broadcast(len(patientsID_case))\n",
    "patientsID_dictionnary_b = sc.broadcast(patientsID_dictionnary)\n",
    "\n",
    "variants=variants_control.unionAll(variants_case)\n",
    "variants_grouped=variants.map(createKey_VariantGene)\n",
    "\n",
    "controlMAF_b=sc.broadcast(controlMAF)\n",
    "caseMAF_b=sc.broadcast(caseMAF)\n",
    "\n",
    "#variants_grouped.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(splitIndex ,v): \n",
    "    return [(splitIndex,list(v))]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1229.80803013\n"
     ]
    }
   ],
   "source": [
    "#start_time = time.time()\n",
    "ntests=0\n",
    "if scope=='monogenic':\n",
    "    if scale=='variant':\n",
    "        ntests=variants_grouped.count()\n",
    "        scores=variants_grouped.map(lambda (k,v):scoreVariant(k,v)).filter(lambda x:x is not None).takeOrdered(1000, key=lambda (k,(v1,v2,v3,v4,v5,v6)): -v1)\n",
    "\n",
    "    #if scale=='gene':\n",
    "    #    variants_grouped_by_gene=variants_grouped.map(geneAsKey).groupByKey()\n",
    "    #    ntests=variants_grouped_by_gene.count()\n",
    "    #    scores=variants_grouped_by_gene.map(lambda (k,v):scoreGene(k,v)).filter(lambda x:x is not None).takeOrdered(1000, key=lambda (k,(v1,v2,v3,v4,v5,v6)): -v1)\n",
    "    if scale=='gene':\n",
    "        variants_grouped_by_gene=variants_grouped.map(geneAsKey).groupByKey()\n",
    "        ntests=variants_grouped_by_gene.count()\n",
    "        burden_by_gene=variants_grouped_by_gene.map(lambda (k,v):(k,burden(v))).repartition(p)\n",
    "        burden_by_gene_with_partitions=burden_by_gene.mapPartitionsWithIndex(lambda splitIndex,v: f(splitIndex,v))\n",
    "        scores=burden_by_gene_with_partitions.flatMap(lambda (k,v):scoreGene(v)).filter(lambda x:x is not None).takeOrdered(1000, key=lambda (k,(v1,v2,v3,v4,v5,v6)): -v1)\n",
    "\n",
    "if scope=='digenic':\n",
    "    if scale=='variant':\n",
    "        variantsID=variants_grouped.keys().map(getVariantID).collect()\n",
    "        variants_grouped_by_pairs=variants_grouped.flatMap(lambda (k,v):createPairs(k[0],v,variantsID)).groupByKey()\n",
    "        scores=variants_grouped_by_pairs.map(lambda (k,v):scoreVariantPair(k,v)).filter(lambda x:x is not None).takeOrdered(1000, key=lambda (k,(variants,v1,v2,v3,v4,v5,v6)): -v1)\n",
    "        ntests=len(variantsID)*(len(variantsID)+1)/2\n",
    "   \n",
    "    if scale=='gene':\n",
    "        variants_grouped_by_gene=variants_grouped.map(geneAsKey).groupByKey()\n",
    "        #variants_grouped_by_gene.cache()\n",
    "        burden_by_gene=variants_grouped_by_gene.map(lambda (k,v):(k,burden(v))).repartition(p)\n",
    "        burden_by_gene_with_partitions=burden_by_gene.mapPartitionsWithIndex(lambda splitIndex,v: f(splitIndex,v))\n",
    "        scores=[]\n",
    "        for i in range(0,p):\n",
    "            block_i=burden_by_gene_with_partitions.filter(lambda (k,v):k==i).collect()[0][1]\n",
    "            score=burden_by_gene_with_partitions.filter(lambda (k,v):k>=0).flatMap(lambda (k,v):scoreGenePair(v,block_i)).takeOrdered(1000, key=lambda (k,(genes,v1,v2,v3,v4,v5,v6)): -v1)\n",
    "            scores=scores+score\n",
    "        scores=sc.parallelize(scores,p).takeOrdered(1000, key=lambda (k,(genes,v1,v2,v3,v4,v5,v6)): -v1)\n",
    "        genesID=variants_grouped_by_gene.keys().collect()\n",
    "        ntests=len(genesID)*(len(genesID)+1)/2\n",
    "    \n",
    "end_time=time.time()\n",
    "runtime=end_time - start_time\n",
    "print(runtime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'CDT1',\n",
       "  (0.2013586956521739,\n",
       "   0.00030908426508244124,\n",
       "   0.21875,\n",
       "   0.017391304347826087,\n",
       "   7.0,\n",
       "   2.0)),\n",
       " (u'KMT2B',\n",
       "  (0.16657608695652174,\n",
       "   0.0063862579538332123,\n",
       "   0.21875,\n",
       "   0.05217391304347826,\n",
       "   7.0,\n",
       "   6.0)),\n",
       " (u'CEP250',\n",
       "  (0.14048913043478262,\n",
       "   0.023287486198645079,\n",
       "   0.21875,\n",
       "   0.0782608695652174,\n",
       "   7.0,\n",
       "   9.0)),\n",
       " (u'ERCC8',\n",
       "  (0.09891304347826087,\n",
       "   0.037736576855819139,\n",
       "   0.125,\n",
       "   0.02608695652173913,\n",
       "   4.0,\n",
       "   3.0)),\n",
       " (u'ARHGAP11B',\n",
       "  (0.09021739130434783,\n",
       "   0.062591120459740093,\n",
       "   0.125,\n",
       "   0.034782608695652174,\n",
       "   4.0,\n",
       "   4.0)),\n",
       " (u'CASK',\n",
       "  (0.07635869565217392,\n",
       "   0.066565108186360758,\n",
       "   0.09375,\n",
       "   0.017391304347826087,\n",
       "   3.0,\n",
       "   2.0)),\n",
       " (u'CENPK',\n",
       "  (0.07635869565217392,\n",
       "   0.066565108186360758,\n",
       "   0.09375,\n",
       "   0.017391304347826087,\n",
       "   3.0,\n",
       "   2.0)),\n",
       " (u'WDR62',\n",
       "  (0.06929347826086957,\n",
       "   0.1638259740370091,\n",
       "   0.15625,\n",
       "   0.08695652173913043,\n",
       "   5.0,\n",
       "   10.0)),\n",
       " (u'PNKP',\n",
       "  (0.04157608695652174,\n",
       "   0.2831785780494554,\n",
       "   0.09375,\n",
       "   0.05217391304347826,\n",
       "   3.0,\n",
       "   6.0))]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores=[analysisName,scale,scope,start_time,end_time,runtime,scores,patientsID_case,patientsID_control,group1name,group2name,ntests]\n",
    "\n",
    "with open(analysisName+'.txt', 'w') as outfile:\n",
    "    json.dump(scores, outfile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
