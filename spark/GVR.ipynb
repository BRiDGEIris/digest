{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import HiveContext\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "\n",
    "content = [line.rstrip() for line in open('jobsArguments.conf')]\n",
    "\n",
    "analysisName=content[0]\n",
    "scope=content[1]\n",
    "scale=content[2]\n",
    "sqlControl=content[3]\n",
    "sqlCase=content[4]\n",
    "group1name=content[5]\n",
    "group2name=content[6]\n",
    "\n",
    "nPartitions=4\n",
    "conf = (SparkConf()\n",
    "         .setMaster(\"local[\"+str(nPartitions)+\"]\")\n",
    "         .setAppName(analysisName)\n",
    "#         .set(\"spark.executor.memory\", \"5g\")\n",
    "#         .set(\"spark.driver.memory\", \"5g\")\n",
    "#         .set(\"spark.python.worker.memory\", \"5g\")\n",
    "       )\n",
    "sc.stop()\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "\n",
    "#parquetFile = sqlContext.read.parquet(\"/user/hive/warehouse/gvr4.db/variantsulb\")\n",
    "#parquetFile = sqlContext.read.parquet(\"/Users/yalb/Projects/Github/Docker/cdh54_4_add1000g/variants2\")\n",
    "#parquetFile = sqlContext.read.parquet(\"hdfs://127.0.0.1:8020/user/hive/warehouse/gvr.db/test\")\n",
    "#parquetFile = sqlContext.read.parquet(\"hdfs://localhost/user/hive/warehouse/gvr3.db/variants\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sqlContext = HiveContext(sc) #sqlContext._get_hive_ctx() #HiveContext(sc) \n",
    "sqlContext = SQLContext(sc)\n",
    "sqlContext.sql(\"SET spark.sql.parquet.binaryAsString=true\")\n",
    "\n",
    "#parquetFile = sqlContext.read.parquet(\"hdfs://node001:8020/user/hive/warehouse/highlander.db/exomes_hc\")\n",
    "\n",
    "parquetFile = sqlContext.read.parquet(\"/Users/yalb/Projects/Github/digest/variantsulb\")\n",
    "parquetFile.registerTempTable(\"parquetFile\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#analysisName=\"control_vs_neurodev_rare_digenic\"\n",
    "#group1name=\"control_ulb_rare_damaging\"\n",
    "#group2name=\"neurodev_ulb_rare_damaging\"\n",
    "scope=\"digenic\"\n",
    "#scale=\"gene\"\n",
    "#controlMAF=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#RDDtest = sqlContext.sql(\"SELECT distinct patient from parquetFile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#RDDtest.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Input is vector patient, chr, pos, ref, alt, gene_symbol, zygosity\n",
    "def createKey_VariantGene(variantData):\n",
    "    #ID is chr:pos:ref:alt\n",
    "    ID=variantData[1]+\":\"+str(variantData[2])+\":\"+variantData[3]+\":\"+variantData[4]\n",
    "    #return ID, gene_symbol, patient, zygosity\n",
    "    zygosity=2\n",
    "    if variantData[6]==\"Heterozygous\":\n",
    "        zygosity=1\n",
    "    patientsID_dictionnary=patientsID_dictionnary_b.value\n",
    "    patientIndex=patientsID_dictionnary[variantData[0]]\n",
    "    return ((ID,variantData[5]),(patientIndex,zygosity))\n",
    "\n",
    "def buildVariantVector(ID,variantData,patientsID):\n",
    "    variantData=list(variantData)\n",
    "    genotype=[0]*len(patientsID)\n",
    "    \n",
    "    #Get sampleID/Genotype for each variant\n",
    "    for i in range(0,len(variantData)):\n",
    "        genotype[variantData[i][1]]=variantData[i][2]\n",
    "    \n",
    "    return ((ID,variantData[0][0]),genotype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#variantGeneEntry: key is (variantID,gene), value is (patientIndex,zygosity)\n",
    "def geneAsKey(variantGeneEntry):    \n",
    "    return (variantGeneEntry[0][1],(variantGeneEntry[0][0],variantGeneEntry[1]))\n",
    "\n",
    "def makePairParts(k,v,nbPart):\n",
    "    result=[]\n",
    "    for i in range(0,nbPart):\n",
    "        result.append(((k,i),v))\n",
    "        \n",
    "    return [(str(sorted([k,i])),(v)) for i in range(0,nbPart)]\n",
    "\n",
    "def f(splitIndex ,v): \n",
    "    return [(splitIndex,list(v))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scoreVariantUnivariate(k,variantData):\n",
    "    variantData=list(variantData)\n",
    "    \n",
    "    score=0\n",
    "    sumControl=0\n",
    "    \n",
    "    sumCase=sum([int(x>0) for x in variantData[0]])\n",
    "    sumControl=sum([int(x>0) for x in variantData[1]])\n",
    "    \n",
    "    score=sumCase#-sumControl\n",
    "    if sumControl>0:\n",
    "        score=0\n",
    "        \n",
    "    if score>0:\n",
    "        return (k,(score,sumCase,sumControl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getGenotypeVectorByGene(gene_symbol,variantList,patientsID_dictionnary,patientsID_split_index):\n",
    "    genoSum=[0]*len(patientsID_dictionnary)\n",
    "    \n",
    "    if len(variantList)>0:\n",
    "        #Go through list of variants\n",
    "        for i in range(0,len(variantList)):\n",
    "            #Get variant ID, and list of sample_index,genotype\n",
    "            (variantID,sample_geno_list)=variantList[i]\n",
    "            sample_geno_list=list(sample_geno_list)\n",
    "            \n",
    "            #Go through list of sample_index,genotype\n",
    "            for j in range(0,len(sample_geno_list)):\n",
    "                genoSum[sample_geno_list[j][0]]=genoSum[sample_geno_list[j][0]]+sample_geno_list[j][1]\n",
    "    return genoSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#variantList is [(locusID,[sample_index,genotype])]\n",
    "def scoreGene(gene_symbol,variantList):\n",
    "    variantList=list(variantList)\n",
    "    \n",
    "    patientsID_dictionnary=patientsID_dictionnary_b.value\n",
    "    genoSum=[0]*len(patientsID_dictionnary)\n",
    "    \n",
    "    patientsID_split_index=patientsID_split_index_b.value\n",
    "    \n",
    "    genoSum=getGenotypeVectorByGene(gene_symbol,variantList,patientsID_dictionnary,patientsID_split_index)\n",
    "    \n",
    "    sumCase=sum([int(x>0) for x in genoSum[0:patientsID_split_index]])\n",
    "    sumControl=sum([int(x>0) for x in genoSum[(patientsID_split_index+1):len(patientsID_dictionnary)]])\n",
    "    score=sumCase-sumControl\n",
    "\n",
    "    if score>0:\n",
    "        return (gene_symbol,(score,sumCase,sumControl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scoreGenePair(gene_symbol_pair,variantList):\n",
    "    \n",
    "    variantList=list(variantList)\n",
    "    \n",
    "    patientsID_dictionnary=patientsID_dictionnary_b.value\n",
    "    \n",
    "    patientsID_split_index=patientsID_split_index_b.value\n",
    "    \n",
    "    score=0\n",
    "    if len(variantList)==2:\n",
    "        (genes,variantList1)=variantList[0]\n",
    "        (genes,variantList2)=variantList[1]\n",
    "        \n",
    "        gene1=genes[0]\n",
    "        gene2=genes[1]\n",
    "        \n",
    "        variantList1=list(variantList1)\n",
    "        variantList2=list(variantList2)\n",
    "        \n",
    "        genoSum1=getGenotypeVectorByGene(gene1,variantList1,patientsID_dictionnary,patientsID_split_index)\n",
    "        genoSum2=getGenotypeVectorByGene(gene2,variantList2,patientsID_dictionnary,patientsID_split_index)\n",
    "        \n",
    "        genoSum=genoSum1+genoSum2\n",
    "        \n",
    "        sumCase=sum([int(x>0) for x in genoSum[0:patientsID_split_index]])\n",
    "        sumControl=sum([int(x>0) for x in genoSum[(patientsID_split_index+1):len(patientsID_dictionnary)]])\n",
    "        \n",
    "        score=sumCase-sumControl\n",
    "\n",
    "        if score>0:\n",
    "            return (gene_symbol_pair,((gene1,gene2),score,sumCase,sumControl))\n",
    "\n",
    "#Key is (variantID, gene)\n",
    "def getGene(variantGene_key):\n",
    "    gene=variantGene_key[1]\n",
    "    \n",
    "    return (gene)\n",
    "\n",
    "def createPairsGenes(k,v,genes):\n",
    "    return [(str(sorted([k,gene])),(sorted([k,gene]),v)) for gene in genes]\n",
    "\n",
    "def fillMissing(k,v):\n",
    "    v=list(v)\n",
    "    if v[0] is None:\n",
    "        v[0]=[0]*len(sample_id_case_b.value)\n",
    "    if v[1] is None:\n",
    "        v[1]=[0]*len(sample_id_control_b.value)\n",
    "        \n",
    "    return (k,v)\n",
    "\n",
    "def fillMissing(k,v):\n",
    "    v=list(v)\n",
    "    if v[1] is None:\n",
    "        v[1]=[0]*len(dict_patient_control_b.value)\n",
    "        \n",
    "    return (k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "variants_case = sqlContext.sql(\"SELECT patient,chr,pos,reference,alternative,gene_symbol,zygosity FROM parquetFile \"+sqlCase)\n",
    "patientsID_case=sorted(variants_case.map(lambda v:v[0]).distinct().collect())\n",
    "\n",
    "if sqlControl!=\"NULL\":\n",
    "    variants_control= sqlContext.sql(\"SELECT patient,chr,pos,reference,alternative,gene_symbol,zygosity FROM parquetFile \"+sqlControl)\n",
    "#    controlMAF=float(controlMAF)\n",
    "else:\n",
    "    variants_control=sc.emptyRDD()\n",
    "#    controlMAF=0   \n",
    "patientsID_control=sorted(variants_control.map(lambda v:v[0]).distinct().collect())\n",
    "\n",
    "patientsID=patientsID_case+patientsID_control\n",
    "patientsID_dictionnary=dict(zip(patientsID,range(len(patientsID))))\n",
    "\n",
    "patientsID_split_index_b=sc.broadcast(len(patientsID_case))\n",
    "\n",
    "patientsID_dictionnary_b = sc.broadcast(patientsID_dictionnary)\n",
    "\n",
    "variants=variants_control.unionAll(variants_case)\n",
    "\n",
    "variants_grouped=variants.map(createKey_VariantGene).groupByKey()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222.242046833\n"
     ]
    }
   ],
   "source": [
    "#start_time = time.time()\n",
    "\n",
    "if scope=='monogenic':\n",
    "    if scale=='variant':\n",
    "        scores=genoMat.map(lambda (k,v):scoreVariantUnivariate(k,v)).filter(lambda x:x is not None).takeOrdered(10000000, key=lambda (k,(v1,v2,v3)): -v1)\n",
    "\n",
    "    if scale=='gene':\n",
    "        scores=variants_grouped.map(geneAsKey).groupByKey().map(lambda (k,v):scoreGene(k,v)).filter(lambda x:x is not None).takeOrdered(1000, key=lambda (k,(v1,v2,v3)): -v1)\n",
    "    \n",
    "if scope=='digenic':\n",
    "    variants_grouped_by_gene=variants_grouped.map(geneAsKey).groupByKey()#.flatMap(lambda (k,v):createPairsGenes(k,v,genes)).groupByKey().map(lambda (k,v):scoreGenePair(k,v))#.filter(lambda x:x is not None).takeOrdered(1000, key=lambda (k,(genes,v1,v2,v3)): -v1)\n",
    "    genes=variants_grouped_by_gene.keys().collect()\n",
    "    scores=variants_grouped_by_gene.flatMap(lambda (k,v):createPairsGenes(k,v,genes)).groupByKey().map(lambda (k,v):scoreGenePair(k,v)).filter(lambda x:x is not None).takeOrdered(1000, key=lambda (k,(genes,v1,v2,v3)): -v1)\n",
    "    \n",
    "end_time=time.time()\n",
    "runtime=end_time - start_time\n",
    "print(runtime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores=variants_grouped.map(geneAsKey).groupByKey().filter(lambda x:x is not None).filter(lambda (k,v):k==\"SREBF1\").map(lambda (k,v):scoreGene(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"[u'CACNA1B', u'PRR21']\", ((u'CACNA1B', u'PRR21'), 2, 10, 8)),\n",
       " (\"[u'OR5P3', u'RPS3A']\", ((u'OR5P3', u'RPS3A'), 2, 2, 0)),\n",
       " (\"[u'ADH6', u'KIAA0513']\", ((u'ADH6', u'KIAA0513'), 2, 2, 0)),\n",
       " (\"[u'ADH6', u'HRCT1']\", ((u'ADH6', u'HRCT1'), 2, 2, 0)),\n",
       " (\"[u'KRT77', u'OSGEPL1']\", ((u'KRT77', u'OSGEPL1'), 2, 2, 0)),\n",
       " (\"[u'ADH6', u'OR11H4']\", ((u'ADH6', u'OR11H4'), 2, 2, 0)),\n",
       " (\"[u'GABPB1', u'WDR89']\", ((u'GABPB1', u'WDR89'), 2, 2, 0)),\n",
       " (\"[u'ADH6', u'TPTE']\", ((u'ADH6', u'TPTE'), 2, 2, 0)),\n",
       " (\"[u'MUC3A', u'RPS3A']\", ((u'MUC3A', u'RPS3A'), 2, 2, 0)),\n",
       " (\"[u'CACNA1B', u'TTC31']\", ((u'CACNA1B', u'TTC31'), 2, 10, 8)),\n",
       " (\"[u'ADH6', u'ZNF99']\", ((u'ADH6', u'ZNF99'), 2, 2, 0)),\n",
       " (\"[u'ADH6', u'CEP170P1']\", ((u'ADH6', u'CEP170P1'), 2, 2, 0)),\n",
       " (\"[u'KIAA0040', u'KRT77']\", ((u'KIAA0040', u'KRT77'), 2, 2, 0)),\n",
       " (\"[u'AC068987.1', u'ADH6']\", ((u'AC068987.1', u'ADH6'), 2, 2, 0)),\n",
       " (\"[u'THNSL2', u'WDR89']\", ((u'THNSL2', u'WDR89'), 2, 2, 0)),\n",
       " (\"[u'ADH6', u'MAP7']\", ((u'ADH6', u'MAP7'), 2, 2, 0)),\n",
       " (\"[u'AP000349.1', u'RPS3A']\", ((u'AP000349.1', u'RPS3A'), 2, 2, 0)),\n",
       " (\"[u'PRR21', u'RASA2']\", ((u'PRR21', u'RASA2'), 2, 3, 1)),\n",
       " (\"[u'ARMCX4', u'BCAM']\", ((u'ARMCX4', u'BCAM'), 2, 2, 0)),\n",
       " (\"[u'AC017028.1', u'WDR89']\", ((u'AC017028.1', u'WDR89'), 2, 2, 0))]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysisName=\"neurodev_vs_control_digenic_rare_high\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores=[analysisName,scale,scope,start_time,end_time,runtime,scores,patientsID_case,patientsID_control,group1name,group2name]\n",
    "\n",
    "with open(analysisName+'.txt', 'w') as outfile:\n",
    "    json.dump(scores, outfile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
